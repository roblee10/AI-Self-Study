# 컨볼루션 모델

# 컨볼루션 필터 계산

$$
O = \frac{I-K+2P}{S} +1
$$

O = 출력 이미지 크기

I = 입력 이미지 크기

K = 컨볼루션 레이어 커널의 사이즈

N = 출력 채널 개수

S = 컨볼루션 연산의 Stride

P = Padding 사이즈

EX1) 

- input = torch.Tensor(24,3,224,224) → 24(개)X3(채널)X224X224(이미지 크기)
- conv = torch.nn.Conv2d(in_channels= 3, out_channels=32, kernel_size=8, stride=4)

I = 224 (입력 이미지 크기)

K =  8 (컨볼루션 커널 사이즈)

N = 32 (출력 채널 개수)

S = 4 (Stride)

P = 0 (default padding)

$$
O = \frac{224-8+2*0}{4} +1 = 55
$$

- output = torch.Tensor(24,32,55,55)
- 96 = 8X8(커널크기) X 32 (채널)

# Batch Normalization 2d

- 문제점: Internal Covariate shift → Batch 별로 분포가 달라지게 됨
- 방법 : 정규 분포(평균 0 분사1) 로 Batch 분포 정규화하
- 효과 :
    - Internal Covariate shift 개선
    - Activation에 들어가게 되는 input range 를 제한
    - learning rate 의 자유도 개선
    - overfitting에 강건해짐
- 한계 :
    - Batch 의 크기가 너무 작으면 데이터 분포 표현을 제대로 못함
    - Batch 크기가 너무 크면 multi modal 형태의  gaussian mixture 모델 형태가 나타날 수 있고, 병렬 연산에 비효율적

사용법

- torch.nn.BatchNorm2d(N, C, H, W)
- N = Batch의 크기
- C = Channel
- H = Height
- W = Width
- C 채널은 필수 입력, 채널값을 기준으로 연산되기 때문